---
title: "Technical Report: Analyzing Factors Influencing Student Academic Success and Dropouts in Higher Education"
author: "Duc Nguyen and Linh Vu"
output: pdf_document
date: "2024-05-10"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, include=FALSE}
library(readr)
student_data <- read_csv('https://archive.ics.uci.edu/static/public/697/data.csv')

library(dplyr)
student_data <- mutate(student_data, `Marital Status` = as.factor(`Marital Status`))
student_data <- mutate(student_data, `Displaced` = as.factor(`Displaced`))
student_data <- mutate(student_data, `Daytime/evening attendance` = as.factor(`Daytime/evening attendance`))
student_data <- mutate(student_data, `Educational special needs` = as.factor(`Educational special needs`))
student_data <- mutate(student_data, `Tuition fees up to date` = as.factor(`Tuition fees up to date`))
student_data <- mutate(student_data, `Gender` = as.factor(`Gender`))
student_data <- mutate(student_data, `Scholarship holder` = as.factor(`Scholarship holder`))
student_data <- mutate(student_data, `Mother's qualification` = as.factor(`Mother's qualification`))
student_data <- mutate(student_data, `Father's qualification` = as.factor(`Father's qualification`))
student_data <- mutate(student_data, `Previous qualification` = as.factor(`Previous qualification`))

names(student_data)[names(student_data) == "Course"] <- "Course_Enrolled"
names(student_data)[names(student_data) == "Nacionality"] <- "Nationality"

student_data <- mutate(student_data, `Nationality` = as.factor(`Nationality`))
student_data <- mutate(student_data, `Course_Enrolled` = as.factor(`Course_Enrolled`))
student_data <- mutate(student_data, `Mother's occupation` = as.factor(`Mother's occupation`))
student_data <- mutate(student_data, `Father's occupation` = as.factor(`Father's occupation`))
student_data <- mutate(student_data, `Debtor` = as.factor(`Debtor`))
student_data <- mutate(student_data, `International` = as.factor(`International`))

library(forcats)

student_data$`Mother's qualification` <- factor(student_data$`Mother's qualification`, levels = c(1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 14, 18, 19, 22, 26, 27, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44))


## Collapse the levels into broader categories
student_data <- mutate(student_data, `Mother's qualification` = fct_collapse(`Mother's qualification`,
    Basic_Education = c("19", "26", "27", "37", "38"),
    Secondary_Education = c("1", "9", "12", "14", "18", "29", "30", "10", "11"),
    Higher_Education = c("2", "3", "4", "5", "6", "40", "41", "42", "43", "44"),
    Professional_Technical = c("22", "39"),
    Unknown_None = c("34", "35", "36", "31", "33")
))

levels(student_data$`Mother's qualification`)

student_data$`Father's qualification` <- factor(student_data$`Father's qualification`, levels = c(1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 14, 18, 19, 22, 26, 27, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44))


## Collapse the levels into broader categories
student_data <- mutate(student_data, `Father's qualification` = fct_collapse(`Father's qualification`,
    Basic_Education = c("19", "26", "27", "37", "38"),
    Secondary_Education = c("1", "9", "12", "14", "18", "29", "30", "10", "11"),
    Higher_Education = c("2", "3", "4", "5", "6", "40", "41", "42", "43", "44"),
    Professional_Technical = c("22", "39"),
    Unknown_None = c("34", "35", "36", "31", "33")
))

levels(student_data$`Father's qualification`)

student_data$`Previous qualification` <- factor(student_data$`Previous qualification`, levels = c(1, 2, 3, 4, 5, 6, 9, 10, 12, 14, 15, 19, 38, 39, 40, 42, 43))

## Collapse the factor levels into broader categories using forcats::fct_collapse
student_data <- mutate(student_data, `Previous qualification` = fct_collapse(`Previous qualification`,
    Basic_Education = c("19", "38"),
    Secondary_Education = c("1", "9", "10", "12", "14", "15"),
    Higher_Education = c("2", "3", "4", "5", "6", "40", "43"),
    Professional_Technical = c("39", "42")
))

## Print the new levels to verify the changes
levels(student_data$`Previous qualification`)

student_data$`Mother's occupation` <- factor(student_data$`Mother's occupation`, levels = c(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 90, 99, 122, 123, 125, 131, 132, 134, 141, 143, 144, 151, 152, 153, 171, 173, 175, 191, 192, 193, 194))

## Collapse the levels into broader categories
student_data <- mutate(student_data, `Mother's occupation` = fct_collapse(`Mother's occupation`,
    Student = "0",
    High_Level_Professionals = c("1", "2", "122", "123", "125"),
    Intermediate_Professionals = c("3", "131", "132", "134"),
    Administrative_Staff = c("4", "141", "143", "144"),
    Service_Workers = c("5", "151", "152", "153", "191"),
    Skilled_Workers = c("6", "7", "171", "173", "175"),
    Operators_Assembly_Workers = c("8"),
    Unskilled_Workers = c("9", "192", "193", "194"),
    Armed_Forces = "10",
    Other_Unknown = c("90", "99")
))

student_data$`Father's occupation` <- factor(student_data$`Father's occupation`, levels = c(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 90, 99, 122, 123, 125, 131, 132, 134, 141, 143, 144, 151, 152, 153, 171, 173, 175, 191, 192, 193, 194))

## Collapse the levels into broader categories
student_data <- mutate(student_data, `Father's occupation` = fct_collapse(`Father's occupation`,
    Student = c("0"),
    High_Level_Professionals = c("1", "2", "122", "123", "125"),
    Intermediate_Professionals = c("3", "131", "132", "134"),
    Administrative_Staff = c("4", "141", "143", "144"),
    Service_Workers = c("5", "151", "152", "153", "191"),
    Skilled_Workers = c("6", "7", "171", "173", "175"),
    Operators_Assembly_Workers = c("8"),
    Unskilled_Workers = c("9", "192", "193", "194"),
    Armed_Forces = "10",
    Other_Unknown = c("90", "99")
))

student_data$`Marital Status` <- factor(student_data$`Marital Status`, levels = c("1", "2", "3", "4", "5", "6"))

student_data$`Marital Status` <- fct_recode(student_data$`Marital Status`,
                                            "Single" = "1",
                                            "Married" = "2",
                                            "Other" = "3",  
                                            "Other" = "4",  
                                            "Other" = "5",  
                                            "Other" = "6")

student_data <- student_data %>%
  mutate(
    `Curricular units all year (enrolled)` = (`Curricular units 1st sem (enrolled)` + `Curricular units 2nd sem (enrolled)`) / 2,
    `Curricular units all year (evaluations)` = (`Curricular units 1st sem (evaluations)` + `Curricular units 2nd sem (evaluations)`) / 2,
    `Curricular units all year (approved)` = (`Curricular units 1st sem (approved)` + `Curricular units 2nd sem (approved)`) / 2,
    `Curricular units all year (grade)` = (`Curricular units 1st sem (grade)` + `Curricular units 2nd sem (grade)`) / 2
  )

## Remove semesterly data - Don't run twice
student_data <- student_data[,-c(22,23,24,25,26,27,28,29,30,31,32,33)]

student_data <- na.omit(student_data)

names(student_data) <- make.names(names(student_data))
student_data$Target <- factor(student_data$Target)
```


# Introduction

The transition from secondary to higher education often poses significant challenges for students, leading to academic difficulties and dropout. This phenomenon critically affects students' future prospects and institutions' reputations and financial stability. Our research investigates the factors influencing student outcomes in higher education, utilizing statistical learning methods to predict student outcomes based on variables such as demographic, socio-economic, and academic information. Specifically, we asked: “What factors are the most predictive of student graduate outcomes in higher education?”

Previous studies primarily focus on predicting academic success using statistical methods. Beaulac and Roosenthal use random forests to predict whether students will complete their program based solely on course grades in college, with 78.84% accuracy.[^1] In addition, Martins et al., whose dataset we will use, achieved a higher accuracy rate for boosting algorithms than random forests, but were yet to incorporate student performance in their first semesters.[^2] Our research will take a step further by adding in early college performance predictors and significantly more observations into our analysis.

[^1]: Cédric Beaulac and Jeffrey S. Rosenthal, "Predicting University Students’ Academic Success and Major Using Random Forests," in *Research in Higher Education* 60, no.7 (2019): 1048-64, doi.org/10.1007/s11162-019-09546-y.
[^2]: Mónica V. Martins et al., "Early Prediction of student’s Performance in Higher Education: A Case Study," in *Trends and Applications in Information Systems and Technologies* 1 (2021): 166-75, doi.org/10.1007/978-3-030-72657-7_16.

# Methods

**Dataset Description**

The dataset of this study was sourced from the UC Irvine Machine Learning Repository, containing records from the Polytechnic Institute of Portalegre, Portugal. The dataset spans the school years 2008-09 and 2018-19, consisting of 4424 student records across various undergraduate degrees. The data features 36 predictors and a categorical response variable indicating student outcomes: `dropout`, `enrolled`, and `graduate`.


**Data Processing**

The data was loaded into RStudio using UCI's URL. Initial data wrangling involved checking for missing values (none found) and recoding categorical variables from numerical to factor types. Further modifications included collapsing the levels of complex categorical variables like parental qualifications and occupations into more general categories for analytical and modeling purposes.


# Exploratory Data Analysis

**Summary Statistics and Data Visualizations**

Key variables were selected based on their potential influence on student outcomes, focusing on factors like parental background, previous academic achievements, and early college performance. Data visualizations included histograms to explore distributions and boxplots to examine relationships between predictors and student outcomes. A correlation analysis was performed to check for multicollinearity, ultimately leading to the combination of variables on early college performance, from semesterly into yearly, in order to reduce redundancy and enhance model interpretability.


**Statistical Methods and Model Diagnostics**

The exploratory analysis utilized forward selection to identify significant predictors. This phase included testing potential variables against the response variable using both visual and statistical methods to ensure only the most relevant predictors were retained. Selected variables were then used to construct a baseline model, planning to employ tree-based classification methods for their robustness in handling non-linear relationships and interactions among predictors.


# Results

For the purpose of our study, we will use two classification models that are able to show the relative predictive power of the independent variables: random forests and boosted trees. Random forest is a tree-based model using ensemble methods. The random forest consists of many trees that are constructed using a random sample of predictors at each split. Random forest is suitable because it automatically performs feature selection. Another advantage of it is that the `randomForest` package allows us to glimpse into the importance of the predictors in our classification. Below is the importance plot of a random forest model with 250 trees and 5 predictors considered at each split.

```{r, include=FALSE}
library(rsample)
set.seed(2024)
my_split <- initial_split(student_data, prop = 0.8, strata = Target)
train_student <- training(my_split)
test_student <- testing(my_split)
```


```{r, include=FALSE}
## Build model
library(randomForest)
set.seed(2024)
rf_mod <- randomForest(Target ~., train_student, ntree = 250, mtry = 5)

## Importance Plot
imp_rf <- as.data.frame(importance(rf_mod))
imp_rf$names <- rownames(imp_rf)
rownames(imp_rf) <- NULL
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(ggplot2)
ggplot(imp_rf, aes(y = reorder(names,MeanDecreaseGini), x = MeanDecreaseGini)) + geom_col() + theme_bw() + labs(x="Mean decrease in Gini coefficient", y="Variables") + ggtitle("Importance Plot from Random Forest")
```

As can be seen, the variables relating to current academic standing and course enrolled in college are the most significant in assessing a student's chance of dropping out. Specifically, the average number of curricular credits approved per semester in the first year was the most predictive, followed by student's average grade in the first year and the course (i.e., the major/concentration at the Portuguese institution). Other variables in the top 10 most important include father's and mother's occupation, whether the tuition fees were paid up to date, and admission grade. For reference, the accuracy rate of this random forest was 77.4%, which was roughly similar to the reviewed literature (all below 80%).

```{r, message=FALSE, warning=FALSE}
library(yardstick)
rf_results <- data.frame(obs = test_student$Target,
                         preds = predict(rf_mod, test_student))
accuracy(rf_results, truth = obs, estimate = preds)
```

We then performed boosted trees using the `tidymodels` framework and `xgboost` engine. Boosted trees are another tree-based ensemble method but with learning feature. That is, each tree is built in the consideration of the previous tree's error. Introducing learning rate into the model has the potential to increase our accuracy rate significantly. Moreover, boosted trees can also give us information on the importance of predictors.



# Discussion


\newpage

# Code Appendix


\newpage

# Bibliography
\setlength{\parindent}{-0.2in}
\setlength{\leftskip}{0.2in}
\setlength{\parskip}{8pt}
\noindent

Beaulac, Cédric, and Jeffrey S. Rosenthal. “Predicting University Students’ Academic Success and Major Using Random Forests.” In *Research in Higher Education* 60, no. 7 (2019): 1048–64. https://doi.org/10.1007/s11162-019-09546-y. 

Martins, Mónica V., Daniel Tolledo, Jorge Machado, Luís M. Baptista, and Valentim Realinho. “Early Prediction of Student’s Performance in Higher Education: A Case Study.” In *Trends and Applications in Information Systems and Technologies* 1 (2021): 166–75. https://doi.org/10.1007/978-3-030-72657-7_16. 